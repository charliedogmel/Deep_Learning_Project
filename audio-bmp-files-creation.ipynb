{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"WARNING: Kernel fails to automatically score if more than one file is saved to disk. You can still download and manually submit prediction. To allow model/spectrograms saving, change setting below.","metadata":{}},{"cell_type":"code","source":"#save_to_disk = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:30:07.453707Z","iopub.execute_input":"2021-09-02T21:30:07.453978Z","iopub.status.idle":"2021-09-02T21:30:07.457458Z","shell.execute_reply.started":"2021-09-02T21:30:07.453952Z","shell.execute_reply":"2021-09-02T21:30:07.456681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install resnest > /dev/null\n!pip install fvcore > /dev/null","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:30:07.463474Z","iopub.execute_input":"2021-09-02T21:30:07.463792Z","iopub.status.idle":"2021-09-02T21:30:26.05451Z","shell.execute_reply.started":"2021-09-02T21:30:07.463766Z","shell.execute_reply":"2021-09-02T21:30:26.053563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport librosa\nimport pandas as pd\nimport numpy as np\nfrom skimage.transform import resize\nfrom PIL import Image\n\nimport os\nimport torch\nimport random\n\nimport torch.utils.data as torchdata\nimport torch.nn as nn\n##from resnest.torch import resnest50\nimport fvcore\n","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:30:26.056707Z","iopub.execute_input":"2021-09-02T21:30:26.05706Z","iopub.status.idle":"2021-09-02T21:30:29.240453Z","shell.execute_reply.started":"2021-09-02T21:30:26.057021Z","shell.execute_reply":"2021-09-02T21:30:29.239693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Generating Mel spectrograms for training from true positive data\n\nOnly need to do this once and then save/download the bmp files to use in another notebook.","metadata":{}},{"cell_type":"code","source":"# fft = 2048\n# hop = 512\n# # Less rounding errors this way\n# sr = 48000\n# length = 10 * sr\n\n# with open('/kaggle/input/rfcx-species-audio-detection/train_tp.csv') as f:\n#     reader = csv.reader(f)\n#     data = list(reader)\n\n# # Check minimum/maximum frequencies for bird calls\n# # Not neccesary, but there are usually plenty of noise in low frequencies, and removing it helps\n# fmin = 24000\n# fmax = 0\n\n# # Skip header row (recording_id,species_id,songtype_id,t_min,f_min,t_max,f_max) and start from 1 instead of 0\n# for i in range(1, len(data)):\n#     if fmin > float(data[i][4]):\n#         fmin = float(data[i][4])\n#     if fmax < float(data[i][6]):\n#         fmax = float(data[i][6])\n# # Get some safety margin\n# fmin = int(fmin * 0.9)\n# fmax = int(fmax * 1.1)\n# print('Minimum frequency: ' + str(fmin) + ', maximum frequency: ' + str(fmax))\n\n\n# print('Starting spectrogram generation')\n# for i in range(1, len(data)):\n#     # All sound files are 48000 bitrate, no need to slowly resample\n#     wav, sr = librosa.load('/kaggle/input/rfcx-species-audio-detection/train/' + data[i][0] + '.flac', sr=None)\n    \n#     t_min = float(data[i][3]) * sr\n#     t_max = float(data[i][5]) * sr\n    \n#     # Positioning sound slice\n#     center = np.round((t_min + t_max) / 2)\n#     beginning = center - length / 2\n#     if beginning < 0:\n#         beginning = 0\n    \n#     ending = beginning + length\n#     if ending > len(wav):\n#         ending = len(wav)\n#         beginning = ending - length\n        \n#     slice = wav[int(beginning):int(ending)]\n    \n#     # Mel spectrogram generation\n#     # Default settings were bad, parameters are adjusted to generate somewhat reasonable quality images\n#     # The better your images are, the better your neural net would perform\n#     # You can also use librosa.stft + librosa.amplitude_to_db instead\n#     mel_spec = librosa.feature.melspectrogram(slice, n_fft=fft, hop_length=hop, sr=sr, fmin=fmin, fmax=fmax, power=1.5)\n#     mel_spec = resize(mel_spec, (224, 400))\n    \n#     # Normalize to 0...1 - this is what goes into neural net\n#     mel_spec = mel_spec - np.min(mel_spec)\n#     mel_spec = mel_spec / np.max(mel_spec)\n\n#     # And this 0...255 is for the saving in bmp format\n#     mel_spec = mel_spec * 255\n#     mel_spec = np.round(mel_spec)    \n#     mel_spec = mel_spec.astype('uint8')\n#     mel_spec = np.asarray(mel_spec)\n    \n#     bmp = Image.fromarray(mel_spec, 'L')\n#     bmp.save('/kaggle/working/' + data[i][0] + '_' + data[i][1] + '_' + str(center) + '.bmp')\n    \n#     if i % 100 == 0:\n#         print('Processed ' + str(i) + ' train examples from ' + str(len(data)))\n\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T21:30:29.241845Z","iopub.execute_input":"2021-09-02T21:30:29.242177Z","iopub.status.idle":"2021-09-02T21:30:29.251573Z","shell.execute_reply.started":"2021-09-02T21:30:29.242141Z","shell.execute_reply":"2021-09-02T21:30:29.250648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating testbmp images from test directory","metadata":{}},{"cell_type":"code","source":"fft = 2048\nhop = 512\nsr = 48000\nlength = 10 * sr\n\ntest_files = os.listdir('/kaggle/input/rfcx-species-audio-detection/test/')\n\n\ndef test_file_to_bmp(f):\n    wav, sr = librosa.load('/kaggle/input/rfcx-species-audio-detection/test/' + f, sr=None)\n\n    # Split for enough segments to not miss anything\n    segments = len(wav) / length\n    segments = int(np.ceil(segments))\n    \n    mel_array = []\n    \n    for i in range(0, segments):\n        # Last segment going from the end\n        if (i + 1) * length > len(wav):\n            slice = wav[len(wav) - length:len(wav)]\n        else:\n            slice = wav[i * length:(i + 1) * length]\n        \n        # Same mel spectrogram as before\n        mel_spec = librosa.feature.melspectrogram(slice, n_fft=fft, hop_length=hop, sr=sr, power=1.5)\n        mel_spec = resize(mel_spec, (224, 400))\n    \n        # Normalize to 0...1 - this is what goes into neural net\n        mel_spec = mel_spec - np.min(mel_spec)\n        mel_spec = mel_spec / np.max(mel_spec)\n        \n        # And this 0...255 is for the saving in bmp format\n        mel_spec = mel_spec * 255\n        mel_spec = np.round(mel_spec)    \n        mel_spec = mel_spec.astype('uint8')\n        mel_spec = np.asarray(mel_spec)\n    \n        bmp = Image.fromarray(mel_spec, 'L')\n        bmp.save('/kaggle/working/' + f.split('.')[0] + '_' + str(i) + '.bmp')\n        \n    return \n\n    \n# Every test file is split on several chunks and prediction is made for each chunk\nfor i in range(0, len(test_files)):\n    test_file_to_bmp(test_files[i])\n    if i % 100 == 0:\n        print('Processed ' + str(i) + ' test examples from ' + str(len(test_files)))\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:30:29.253011Z","iopub.execute_input":"2021-09-02T21:30:29.253731Z","iopub.status.idle":"2021-09-02T21:42:24.62583Z","shell.execute_reply.started":"2021-09-02T21:30:29.253691Z","shell.execute_reply":"2021-09-02T21:42:24.625026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Settings and random seeds initialization for reproducible results","metadata":{}},{"cell_type":"code","source":"# num_birds = 24\n# # 6GB GPU-friendly (~4 GB used by model)\n# # Increase if neccesary\n# batch_size = 16\n\n# # This is enough to exactly reproduce results on local machine (Windows / Turing GPU)\n# # Kaggle GPU kernels (Linux / Pascal GPU) are not deterministic even with random seeds set\n# # Your score might vary a lot (~up to 0.05) on a different runs due to picking different epochs to submit\n# rng_seed = 1234\n# random.seed(rng_seed)\n# np.random.seed(rng_seed)\n# os.environ['PYTHONHASHSEED'] = str(rng_seed)\n# torch.manual_seed(rng_seed)\n# torch.cuda.manual_seed(rng_seed)\n# torch.backends.cudnn.deterministic = True\n# torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.63014Z","iopub.execute_input":"2021-09-02T21:42:24.630411Z","iopub.status.idle":"2021-09-02T21:42:24.636739Z","shell.execute_reply.started":"2021-09-02T21:42:24.630378Z","shell.execute_reply":"2021-09-02T21:42:24.635985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model dataset class","metadata":{}},{"cell_type":"code","source":"# class RainforestDataset(torchdata.Dataset):\n#     def __init__(self, filelist):\n#         self.specs = []\n#         self.labels = []\n#         for f in filelist:\n#             # Easier to pass species in filename at the start; worth changing later to more capable method\n#             label = int(str.split(f, '_')[1])\n#             label_array = np.zeros(num_birds, dtype=np.single)\n#             label_array[label] = 1.\n#             self.labels.append(label_array)\n            \n#             # Open and save spectrogram to memory\n            \n#             # If you use more spectrograms (add train_fp, for example), then they would not all fit to memory\n#             # In this case you should load them on the fly in __getitem__\n#             img = Image.open('/kaggle/working/' + f)\n#             mel_spec = np.array(img)\n#             img.close()\n            \n#             # Transforming spectrogram from bmp to 0..1 array\n#             mel_spec = mel_spec / 255\n#             # Stacking for 3-channel image for resnet\n#             mel_spec = np.stack((mel_spec, mel_spec, mel_spec))\n            \n#             self.specs.append(mel_spec)\n    \n#     def __len__(self):\n#         return len(self.specs)\n    \n#     def __getitem__(self, item):\n#         # Augment here if you want\n#         return self.specs[item], self.labels[item]","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.640535Z","iopub.execute_input":"2021-09-02T21:42:24.640822Z","iopub.status.idle":"2021-09-02T21:42:24.650548Z","shell.execute_reply.started":"2021-09-02T21:42:24.640777Z","shell.execute_reply":"2021-09-02T21:42:24.649818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split training set on training and validation  \n  \nWhat StratifiedKFold does:  \n![StratifiedKFold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_003.png)","metadata":{}},{"cell_type":"code","source":"# file_list = []\n# label_list = []\n\n# for f in os.listdir('/kaggle/working/'):\n#     if '.bmp' in f:\n#         file_list.append(f)\n#         label = str.split(f, '_')[1]\n#         label_list.append(label)\n\n\n# from sklearn.model_selection import StratifiedKFold\n\n# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng_seed)\n\n# train_files = []\n# val_files = []\n\n# for fold_id, (train_index, val_index) in enumerate(skf.split(file_list, label_list)):\n#     # Picking only first fold to train/val on\n#     # This means loss of 20% training data\n#     # To avoid this, you can train 5 different models on 5 folds and average predictions\n#     if fold_id == 0:\n#         train_files = np.take(file_list, train_index)\n#         val_files = np.take(file_list, val_index)\n\n# print('Training on ' + str(len(train_files)) + ' examples')\n# print('Validating on ' + str(len(val_files)) + ' examples')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.653941Z","iopub.execute_input":"2021-09-02T21:42:24.654313Z","iopub.status.idle":"2021-09-02T21:42:24.660998Z","shell.execute_reply.started":"2021-09-02T21:42:24.654275Z","shell.execute_reply":"2021-09-02T21:42:24.660026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparing everything for training","metadata":{}},{"cell_type":"code","source":"# # get list of models\n# torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n# # load pretrained models, using ResNeSt-50 as an example\n# model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n# model.eval()\n\n\n# train_dataset = RainforestDataset(train_files)\n# val_dataset = RainforestDataset(val_files)\n\n# train_loader = torchdata.DataLoader(train_dataset, batch_size=batch_size, sampler=torchdata.RandomSampler(train_dataset))\n# val_loader = torchdata.DataLoader(val_dataset, batch_size=batch_size, sampler=torchdata.RandomSampler(val_dataset))\n\n# # ResNeSt: Split-Attention Networks\n# # https://arxiv.org/abs/2004.08955\n# # Significantly outperforms standard Resnet\n# ##model = resnest50(pretrained=True)\n\n# model.fc = nn.Sequential(\n#     nn.Linear(2048, 1024),\n#     nn.ReLU(),\n#     nn.Dropout(p=0.2),\n#     nn.Linear(1024, 1024),\n#     nn.ReLU(),\n#     nn.Dropout(p=0.2),\n#     nn.Linear(1024, num_birds)\n# )\n\n# # Picked for this notebook; pick new ones after major changes (such as adding train_fp to train data)\n# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n\n# # This loss function is not exactly suited for competition metric, which only cares about ranking of predictions\n# # Exploring different loss fuctions would be a good idea\n# pos_weights = torch.ones(num_birds)\n# pos_weights = pos_weights * num_birds\n# loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n\n# if torch.cuda.is_available():\n#     model = model.cuda()\n#     loss_function = loss_function.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.663329Z","iopub.execute_input":"2021-09-02T21:42:24.663737Z","iopub.status.idle":"2021-09-02T21:42:24.674141Z","shell.execute_reply.started":"2021-09-02T21:42:24.663702Z","shell.execute_reply":"2021-09-02T21:42:24.673223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training model on saved spectrograms","metadata":{}},{"cell_type":"code","source":"# best_corrects = 0\n\n# # Train loop\n# print('Starting training loop')\n# for e in range(0, 32):\n#     # Stats\n#     train_loss = []\n#     train_corr = []\n    \n#     # Single epoch - train\n#     model.train()\n#     for batch, (data, target) in enumerate(train_loader):\n#         data = data.float()\n#         if torch.cuda.is_available():\n#             data, target = data.cuda(), target.cuda()\n            \n#         optimizer.zero_grad()\n        \n#         output = model(data)\n#         loss = loss_function(output, target)\n        \n#         loss.backward()\n#         optimizer.step()\n        \n#         # Stats\n#         vals, answers = torch.max(output, 1)\n#         vals, targets = torch.max(target, 1)\n#         corrects = 0\n#         for i in range(0, len(answers)):\n#             if answers[i] == targets[i]:\n#                 corrects = corrects + 1\n#         train_corr.append(corrects)\n        \n#         train_loss.append(loss.item())\n    \n#     # Stats\n#     for g in optimizer.param_groups:\n#         lr = g['lr']\n#     print('Epoch ' + str(e) + ' training end. LR: ' + str(lr) + ', Loss: ' + str(sum(train_loss) / len(train_loss)) +\n#           ', Correct answers: ' + str(sum(train_corr)) + '/' + str(train_dataset.__len__()))\n    \n#     # Single epoch - validation\n#     with torch.no_grad():\n#         # Stats\n#         val_loss = []\n#         val_corr = []\n        \n#         model.eval()\n#         for batch, (data, target) in enumerate(val_loader):\n#             data = data.float()\n#             if torch.cuda.is_available():\n#                 data, target = data.cuda(), target.cuda()\n            \n#             output = model(data)\n#             loss = loss_function(output, target)\n            \n#             # Stats\n#             vals, answers = torch.max(output, 1)\n#             vals, targets = torch.max(target, 1)\n#             corrects = 0\n#             for i in range(0, len(answers)):\n#                 if answers[i] == targets[i]:\n#                     corrects = corrects + 1\n#             val_corr.append(corrects)\n        \n#             val_loss.append(loss.item())\n    \n#     # Stats\n#     print('Epoch ' + str(e) + ' validation end. LR: ' + str(lr) + ', Loss: ' + str(sum(val_loss) / len(val_loss)) +\n#           ', Correct answers: ' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()))\n    \n#     # If this epoch is better than previous on validation, save model\n#     # Validation loss is the more common metric, but in this case our loss is misaligned with competition metric, making accuracy a better metric\n#     if sum(val_corr) > best_corrects:\n#         print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n#         torch.save(model, 'best_model.pt')\n#         best_corrects = sum(val_corr)\n        \n#     # Call every epoch\n#     scheduler.step()\n\n# # Free memory\n# del model","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.677374Z","iopub.execute_input":"2021-09-02T21:42:24.677757Z","iopub.status.idle":"2021-09-02T21:42:24.687097Z","shell.execute_reply.started":"2021-09-02T21:42:24.677731Z","shell.execute_reply":"2021-09-02T21:42:24.686467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to split and load one test file","metadata":{}},{"cell_type":"code","source":"# # Already defined above; for reference\n\n# # fft = 2048\n# # hop = 512\n# # sr = 48000\n# # length = 10 * sr\n\n# def load_test_file(f):\n#     wav, sr = librosa.load('/kaggle/input/rfcx-species-audio-detection/test/' + f, sr=None)\n\n#     # Split for enough segments to not miss anything\n#     segments = len(wav) / length\n#     segments = int(np.ceil(segments))\n    \n#     mel_array = []\n    \n#     for i in range(0, segments):\n#         # Last segment going from the end\n#         if (i + 1) * length > len(wav):\n#             slice = wav[len(wav) - length:len(wav)]\n#         else:\n#             slice = wav[i * length:(i + 1) * length]\n        \n#         # Same mel spectrogram as before\n#         mel_spec = librosa.feature.melspectrogram(slice, n_fft=fft, hop_length=hop, sr=sr, fmin=fmin, fmax=fmax, power=1.5)\n#         mel_spec = resize(mel_spec, (224, 400))\n    \n#         mel_spec = mel_spec - np.min(mel_spec)\n#         mel_spec = mel_spec / np.max(mel_spec)\n        \n#         mel_spec = np.stack((mel_spec, mel_spec, mel_spec))\n\n#         mel_array.append(mel_spec)\n    \n#     return mel_array","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.690321Z","iopub.execute_input":"2021-09-02T21:42:24.690671Z","iopub.status.idle":"2021-09-02T21:42:24.700777Z","shell.execute_reply.started":"2021-09-02T21:42:24.690647Z","shell.execute_reply":"2021-09-02T21:42:24.700038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submitting predictions with best model","metadata":{}},{"cell_type":"code","source":"# # Loading model back\n# ##model = resnest50(pretrained=True)\n# model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n\n# model.fc = nn.Sequential(\n#     nn.Linear(2048, 1024),\n#     nn.ReLU(),\n#     nn.Dropout(p=0.2),\n#     nn.Linear(1024, 1024),\n#     nn.ReLU(),\n#     nn.Dropout(p=0.2),\n#     nn.Linear(1024, num_birds)\n# )\n\n# model = torch.load('/kaggle/working/best_model.pt')\n# model.eval()\n\n# # Scoring does not like many files:(\n# # if save_to_disk == 0:\n# #     for f in os.listdir('/kaggle/working/'):\n# #         os.remove('/kaggle/working/' + f)\n\n# if torch.cuda.is_available():\n#     model.cuda()\n    \n# # Prediction loop\n# print('Starting prediction loop')\n# with open('submission.csv', 'w', newline='') as csvfile:\n#     submission_writer = csv.writer(csvfile, delimiter=',')\n#     submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n#                                's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n#     new_rows = []\n#     sub_df = pd.DataFrame(columns = ['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n#                                      's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n# #     print(sub_df)\n    \n#     test_files = os.listdir('/kaggle/input/rfcx-species-audio-detection/test/')\n#     print(len(test_files))\n    \n#     # Every test file is split on several chunks and prediction is made for each chunk\n#     for i in range(0, len(test_files)):\n#         data = load_test_file(test_files[i])\n#         data = torch.tensor(data)\n#         data = data.float()\n#         if torch.cuda.is_available():\n#             data = data.cuda()\n\n#         output = model(data)\n\n#         # Taking max prediction from all slices per bird species\n#         # Usually you want Sigmoid layer here to convert output to probabilities\n#         # In this competition only relative ranking matters, and not the exact value of prediction, so we can use it directly\n#         maxed_output = torch.max(output, dim=0)[0]\n#         maxed_output = maxed_output.cpu().detach()\n        \n#         file_id = str.split(test_files[i], '.')[0]\n#         write_array = [file_id]\n        \n#         for out in maxed_output:\n#             write_array.append(out.item())\n    \n#         submission_writer.writerow(write_array)\n#         new_rows.append(write_array)\n# #         sub_df = sub_df.append(pd.DataFrame(new_row, \n# #                                 columns = ['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n# #                                            's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23']), \n# #                                ignore_index=True)\n        \n#         if i % 100 == 0 and i > 0:\n#             print('Predicted for ' + str(i) + ' of ' + str(len(test_files) + 1) + ' files')\n\n\n# sub_df = sub_df.append(pd.DataFrame(new_rows, \n#                                     columns = ['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n#                                                's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23']), \n#                                     ignore_index=True)\n# print('Submission generated')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.703463Z","iopub.execute_input":"2021-09-02T21:42:24.704473Z","iopub.status.idle":"2021-09-02T21:42:24.71242Z","shell.execute_reply.started":"2021-09-02T21:42:24.704445Z","shell.execute_reply":"2021-09-02T21:42:24.711784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.715069Z","iopub.execute_input":"2021-09-02T21:42:24.716174Z","iopub.status.idle":"2021-09-02T21:42:24.726456Z","shell.execute_reply.started":"2021-09-02T21:42:24.716147Z","shell.execute_reply":"2021-09-02T21:42:24.72576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df.to_csv('/kaggle/working/test_results.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T21:42:24.729228Z","iopub.execute_input":"2021-09-02T21:42:24.729506Z","iopub.status.idle":"2021-09-02T21:42:24.736299Z","shell.execute_reply.started":"2021-09-02T21:42:24.72948Z","shell.execute_reply":"2021-09-02T21:42:24.735399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}